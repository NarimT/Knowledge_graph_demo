# ğŸ§  Knowledge Graph + Personality Extraction Pipeline

A compact, reproducible pipeline that extracts a **document-level Knowledge Graph (KG)** â€” entities, relations, and inferred **Big-5 personality traits** â€” from short texts.  
Designed for clarity, reproducibility, and to demonstrate LLM-assisted workflows (prompt chains, provenance, and evaluation).

---

### â–¶ï¸ Quick links

* **Demo notebook:** `notebooks/03_pipeline_demo.ipynb`
* **Synthetic data:** `data/synthetic_v1.json`
* **Prompts:** `prompts/`
* **Saved LLM outputs:** `llm_session/raw_responses.json`
* **Outputs:** `notebooks_output/`
* **Core code:** `src/`
* **Tests:** `test_pipeline.py`
* **Shared session walkthrough:** [View explanation on ChatGPT â†—ï¸](https://chatgpt.com/share/68f6e1e9-29e8-8008-aacf-79c786f7106a)

---

### âš¡ Highlights

* Modular pipeline: **chunk â†’ NER â†’ coref â†’ RE â†’ normalize â†’ personality â†’ KG**  
* Works fully offline with synthetic data; optional LLM calls are supported and logged  
* Outputs include: normalized triples, canonical entity nodes, per-person Big-5 scores (with evidence quotes), and NetworkX KG visualizations  
* Focus: clean design, repeatable prompts, and rigorous evaluation (Precision/Recall/F1 for triples; MAE/Pearson for personality)

---

### ğŸš€ Quick start (local)

1. **Create environment and install dependencies**

```bash
python -m venv .venv
source .venv/bin/activate        # macOS / Linux
# .venv\Scripts\activate         # Windows PowerShell
pip install -r requirements.txt
python -m spacy download en_core_web_sm
(Optional) Enable LLM calls

bash
Copy code
export OPENAI_API_KEY="sk-..."   # macOS / Linux
# setx OPENAI_API_KEY "sk-..."   # Windows (PowerShell)
Run the demo notebook

bash
Copy code
jupyter notebook notebooks/03_pipeline_demo.ipynb
ğŸ§© What the notebook does
Loads data/synthetic_v1.json (gold-labeled synthetic docs)

Runs spaCy NER and a compact SVO extractor (OpenIE-lite)

(Optional) Calls LLM for relation extraction or personality inference (prompt chain logged)

Normalizes verbs and canonicalizes mentions

Builds a KG with networkx, adds has_trait edges with numeric scores

Evaluates: Precision/Recall/F1 for triples; MAE & Pearson for personality traits

Saves all artifacts to notebooks_output/ and raw LLM logs to llm_session/

ğŸ§ª Run tests
bash
Copy code
pytest -q
If tests fail because the spaCy model is missing:

bash
Copy code
python -m spacy download en_core_web_sm
ğŸ“‚ Repository structure
graphql
Copy code
.
â”œâ”€ data/                     # synthetic dataset (synthetic_v1.json)
â”œâ”€ notebooks/                # demo notebooks (03_pipeline_demo.ipynb)
â”œâ”€ prompts/                  # LLM prompt templates (chunk, NER, RE, normalize, personality)
â”œâ”€ src/                      # extractors, normalize, llm_client, kg_builder, eval
â”œâ”€ notebooks_output/         # exported graphs, jsons, evaluation results
â”œâ”€ llm_session/              # saved prompt inputs + raw LLM outputs (traceability)
â”œâ”€ test_pipeline.py          # pytest unit tests
â”œâ”€ report/design_choices.md  # 1â€“1.5 page design summary
â”œâ”€ requirements.txt
â””â”€ README.md
âœ… Reproducibility & grading checklist
Please include the following in your submission:

data/synthetic_v1.json â€” gold labels and Big-5 traits

notebooks/03_pipeline_demo.ipynb â€” main pipeline notebook

prompts/ â€” exact prompt templates and examples

llm_session/raw_responses.json â€” raw model outputs with metadata

src/ â€” code modules for extraction and KG building

notebooks_output/ â€” generated KG, evaluation results

report/design_choices.md â€” design justification, â€œChatGPT-assistedâ€ noted

README.md â€” this file

ğŸ“ˆ Evaluation details
Triples: normalized (subject, predicate, object) exact-match
â†’ reports Precision, Recall, and F1

Personality: per-trait Mean Absolute Error (MAE) & Pearson correlation
â†’ evaluates Big-5 score prediction quality

Qualitative: error samples and evidence-based analysis (optional)

ğŸ§  Notes on LLM workflow & ethics
The pipeline uses a chain-of-prompts strategy â€” smaller micro-tasks instead of one big model call:
chunk â†’ NER â†’ coref â†’ RE â†’ normalize â†’ personality

All LLM outputs are validated with schema checks and evidence grounding.

Ethical note: this demo uses synthetic data only. Personality inference on real people without consent should be avoided.

